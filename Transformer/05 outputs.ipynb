{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "086622b1-139d-458a-9da3-360cbd6a37f8",
   "metadata": {},
   "source": [
    "### Outputs\n",
    "- forward: embedding => encode => pooling\n",
    "- len(outputs) : 3\n",
    "- outputs[0]\n",
    "  - last_hidden_state, shape: batch_size * seq_len * hidden_size (torch.Size([1, 36, 768]))\n",
    "- outputs[1]\n",
    "  - pooler_state, shape: batch_size * hidden_size (torch.Size([1, 768]))\n",
    "  - the last layer hidden state of the first token of the sequence. ([CLS]\n",
    "- outputs[2], only available when output_hidden_states = True or model.config.output_hidden_states = True\n",
    "  - combination of embeddings outputs(1) + outputs of each hidden layer (12)\n",
    "     - (1+12) * batch_size * seq_len * hidden_size (13*1*36*768)\n",
    "- outputs[0] == outputs[2][-1]\n",
    "- outputs[1] == model.pooler(outputs[2][-1])\n",
    "- outputs[2][0] == model.embeddings(token_input['input_ids'], token_input['token_type_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eea6209-8eee-4d66-819e-d26d41504ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "model_name = 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25305888-9d3b-4e5a-82a6-b8ff9146571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name, output_hidden_states = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "477d1d7b-4b98-4a42-8976-75d0898f3bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2023,  2817,  3640,  1037,  4800, 10755, 13143,  4106,  1997,\n",
       "          1996, 11343,  1997,  2833,  3573, 11730,  1999,  1996,  2149,  1998,\n",
       "         12054, 10085, 18963,  2015,  2007,  5101,  6459,  2006,  2679,  1010,\n",
       "         18240,  1998, 17522, 23035,  3570,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = 'This study provides a multivariate analysis of the availability of food store outlets in the US and'\\\n",
    "'associations with neighborhood characteristics on race, ethnicity and socioeconomic status'\n",
    "\n",
    "token_input = tokenizer(sent1, return_tensors='pt')\n",
    "token_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39eff388-2318-4ee6-bcc7-582b6d606e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  101,  2023,  2817,  3640,  1037,  4800, 10755, 13143,  4106,  1997,\n",
       "           1996, 11343,  1997,  2833,  3573, 11730,  1999,  1996,  2149,  1998,\n",
       "          12054, 10085, 18963,  2015,  2007,  5101,  6459,  2006,  2679,  1010,\n",
       "          18240,  1998, 17522, 23035,  3570,   102]]),\n",
       " torch.Size([1, 36]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_input['input_ids'], token_input['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc4920dc-27f1-464f-b5f7-3c8b915b4e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**token_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee900c84-f966-4558-b415-53fe8fe524f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13407dac-9f65-4446-8e50-612dd7440e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0] == outputs[2][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83ae1c29-008c-468c-8f87-0a1d2f81dca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 36, 768]), torch.Size([1, 768]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].shape, outputs[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e5ab2c5-80cb-45ad-9008-11edea10982b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[1] == model.pooler(outputs[2][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3285a627-e525-42a8-8c80-ae49d4b70b7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1686, -0.2858, -0.3261,  ..., -0.0276,  0.0383,  0.1640],\n",
       "         [-0.6485,  0.6739, -0.0932,  ...,  0.4475,  0.6696,  0.1820],\n",
       "         [-0.0772,  0.9152, -0.2559,  ...,  0.3321,  1.2170, -0.3592],\n",
       "         ...,\n",
       "         [-0.6935, -0.6749, -0.4088,  ..., -0.7283,  0.3733, -1.6357],\n",
       "         [ 1.0875,  0.0683,  1.1294,  ..., -0.9309,  0.7401,  0.4236],\n",
       "         [-0.0908, -0.2099,  0.0628,  ..., -0.7465,  0.4288, -0.2265]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings(token_input['input_ids'], token_input['token_type_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9048c8eb-831d-4795-b3ee-b500c02056f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[2][0] ==model.embeddings(token_input['input_ids'], token_input['token_type_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b282bc0-1e96-4e32-b546-8915dc56e349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
